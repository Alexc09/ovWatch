{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6951cc71-7a47-44f2-817e-3e1d26cb60a2",
   "metadata": {},
   "source": [
    "### Commands\n",
    "python detect.py --weights ../yolov5m6.pt --img 1024 --conf 0.25 --source 0\n",
    "\n",
    "## References\n",
    "https://github.com/ultralytics/yolov5/issues/36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260726c6-2593-42c0-928d-9ce96c83c0fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d7dbcb-0839-4995-bf0a-a94fc4cb489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "from ctypes import windll\n",
    "from IPython.display import clear_output, display\n",
    "import time\n",
    "from win32 import win32api\n",
    "import win32con\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mss\n",
    "import numpy as np\n",
    "from PIL import Image, ImageGrab\n",
    "import pandas as pd\n",
    "import pyautogui\n",
    "import random\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bed299e-0e88-4109-b037-06adda9e8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "1.11.0+cu113\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc230854-82d1-449c-99cc-c9ad94811bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"labels.txt\", \"r\")\n",
    "content = file.read()\n",
    "labels = content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c73045c-8009-43bd-9ba7-760755c7975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBOX_COLORS = [(255,97,3), (255,64,64), (127,255,212), (227,207,87), (118,238,0)]\n",
    "BBOX_THICKNESS = 2\n",
    "\n",
    "FONT_FAMILY = cv2.FONT_HERSHEY_DUPLEX\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "TEXT_SIZE = 0.8\n",
    "TEXT_THICKNESS = 2\n",
    "\n",
    "color = (255,153,51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0519e5b3-6262-4fec-8cf0-9921bc672f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\alexc/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-6-26 Python-3.8.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m6 summary: 378 layers, 35704908 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39ba292-f5fd-4af4-9e0d-ca608870f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conf = 0.25  # NMS confidence threshold\n",
    "model.iou = 0.45  # NMS IoU threshold\n",
    "model.agnostic = False  # NMS class-agnostic\n",
    "model.multi_label = False  # NMS multiple labels per box\n",
    "model.classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n",
    "model.max_det = 1000  # maximum number of detections per image\n",
    "model.amp = False   # Automatic Mixed Precision (AMP) inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79c888-bb3d-4bbe-ad1a-ee69c0ca6a26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using file image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "055fbd62-e1ab-4391-87d9-43efb729ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"bus.jpg\")\n",
    "# img = cv2.imread(\"bus.jpg\")[..., ::-1]  # OpenCV image (BGR to RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80bacb17-345c-427f-a805-16ed5eba462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(img, size=640)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319faaa-d7fb-4720-a4f9-25f5d8e0799d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd2e1c-f2e6-4838-be5c-20b7a4bc9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "  \n",
    "while(True):\n",
    "    # Camera capture\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame)\n",
    "    for result in results.xyxy[0]:\n",
    "        np_result = result.cpu().detach().numpy()\n",
    "        xmin, ymin, xmax, ymax, confidence, class_name = np_result\n",
    "        xmin, ymin, xmax, ymax, class_name = list(map(lambda a:int(a), (xmin, ymin, xmax, ymax, class_name)))\n",
    "        \n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, BBOX_THICKNESS)\n",
    "        \n",
    "        label = labels[class_name]\n",
    "        confidence = str(confidence.round(2))\n",
    "        text = f\"{label}: {confidence}\"\n",
    "        \n",
    "        (w, h), _ = cv2.getTextSize(text, FONT_FAMILY, TEXT_SIZE, 1)\n",
    "        cv2.rectangle(frame, (xmin, ymin-h), (xmin+w, ymin), color, -1)\n",
    "        cv2.putText(frame, text, (xmin, ymin), FONT_FAMILY, TEXT_SIZE, TEXT_COLOR, TEXT_THICKNESS)\n",
    "  \n",
    "    cv2.imshow('frame', frame)\n",
    "      \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd97a991-8cdd-4933-8416-577c2fa6ca43",
   "metadata": {},
   "source": [
    "### Using computer screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3403a85-18e1-45b3-9cb4-30b5ab9b764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'left': -2880, 'top': 0, 'width': 5440, 'height': 1620}\n",
      "{'left': 0, 'top': 0, 'width': 2560, 'height': 1600}\n",
      "{'left': -2880, 'top': 0, 'width': 2880, 'height': 1620}\n"
     ]
    }
   ],
   "source": [
    "with mss.mss() as mss_instance:\n",
    "    for monitor in mss_instance.monitors:\n",
    "        print(monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c1f3ce-ea16-4ff1-a37b-2e63f299d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOUSEEVENTF_MOVE = 0x0001 # mouse move \n",
    "MOUSEEVENTF_LEFTDOWN = 0x0002 # left button down \n",
    "MOUSEEVENTF_LEFTUP = 0x0004 # left button up \n",
    "MOUSEEVENTF_RIGHTDOWN = 0x0008 # right button down \n",
    "MOUSEEVENTF_RIGHTUP = 0x0010 # right button up \n",
    "MOUSEEVENTF_MIDDLEDOWN = 0x0020 # middle button down \n",
    "MOUSEEVENTF_MIDDLEUP = 0x0040 # middle button up \n",
    "MOUSEEVENTF_WHEEL = 0x0800 # wheel button rolled \n",
    "MOUSEEVENTF_ABSOLUTE = 0x8000 # absolute move \n",
    "    \n",
    "# Moves the mouse cursor to position (final_x, final_y)\n",
    "def move_mouse(final_x, final_y):\n",
    "    curr_x, curr_y = pyautogui.position()\n",
    "    print(f\"Current position {(curr_x, curr_y)}\")\n",
    "    windll.user32.mouse_event(MOUSEEVENTF_MOVE + MOUSEEVENTF_ABSOLUTE, final_x, final_y, 0,0)\n",
    "    pyautogui.mouseDown(button='left')\n",
    "    \n",
    "def get_mouse_position():\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(0.5)\n",
    "            clear_output(wait=True)\n",
    "            print(pyautogui.position())\n",
    "        except KeyboardInterrupt:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f54638b8-3470-4b8f-99fd-07bdcf95933a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target position: (1400, 1001)\n",
      "Current position (1280, 800)\n"
     ]
    }
   ],
   "source": [
    "sct = mss.mss()\n",
    "\n",
    "MONITOR = {\n",
    "    \"COMPUTER\": sct.monitors[1],\n",
    "    \"EXTERNAL\": sct.monitors[2]\n",
    "}\n",
    "\n",
    "START_POS = {\n",
    "    \"COMPUTER\": (300, 300),\n",
    "    \"EXTERNAL\": (-300, 200)\n",
    "}\n",
    "\n",
    "# window where the game is being played on (COMPUTER/EXTERNAL)\n",
    "SOURCE_WINDOW = \"COMPUTER\"\n",
    "\n",
    "# Tab into the game computer window\n",
    "pyautogui.moveTo(START_POS[SOURCE_WINDOW])\n",
    "pyautogui.click()\n",
    "\n",
    "while True:\n",
    "# for _ in range(100):\n",
    "    screenShot = sct.grab(MONITOR[SOURCE_WINDOW])\n",
    "    frame = Image.frombytes(\n",
    "        'RGB', \n",
    "        (screenShot.width, screenShot.height), \n",
    "        screenShot.rgb, \n",
    "    )\n",
    "    frame = np.array(frame)\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame)\n",
    "    for result in results.xyxy[0]:\n",
    "        np_result = result.cpu().detach().numpy()\n",
    "        xmin, ymin, xmax, ymax, confidence, class_name = np_result\n",
    "        xmin, ymin, xmax, ymax, class_name = list(map(lambda a:int(a), (xmin, ymin, xmax, ymax, class_name)))\n",
    "        \n",
    "        if labels[class_name] != \"person\":\n",
    "            continue\n",
    "            \n",
    "        # Calculate the final position where the cursor should be\n",
    "        # The x coordinate should be the middle\n",
    "        final_x = int((xmin + xmax)/2)\n",
    "        # The y coordinate should be a little higher than the centre (30% from the top rather than the 50% middle)\n",
    "        final_y = int(ymin + (ymax - ymin)*0.3)\n",
    "        \n",
    "        # Clear output for clean printing to the notebook\n",
    "        clear_output(wait=True)\n",
    "        cv2.circle(frame, (final_x, final_y), 3, (0,255,0), -1)\n",
    "        print(f\"Target position: {(final_x, final_y)}\")\n",
    "        \n",
    "        move_mouse(final_x, final_y)\n",
    "        \n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, BBOX_THICKNESS)\n",
    "        \n",
    "        label = labels[class_name]\n",
    "        confidence = str(confidence.round(2))\n",
    "        text = f\"{label}: {confidence}\"\n",
    "        \n",
    "        (w, h), _ = cv2.getTextSize(text, FONT_FAMILY, TEXT_SIZE, 1)\n",
    "        cv2.rectangle(frame, (xmin, ymin-h), (xmin+w, ymin), color, -1)\n",
    "        cv2.putText(frame, text, (xmin, ymin), FONT_FAMILY, TEXT_SIZE, TEXT_COLOR, TEXT_THICKNESS)\n",
    "  \n",
    "    cv2.imshow('frame', cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "      \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
